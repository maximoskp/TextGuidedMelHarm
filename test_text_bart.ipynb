{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_utils import SeparatedMelHarmTextDataset, MelHarmTextCollatorForSeq2Seq\n",
    "import os\n",
    "import numpy as np\n",
    "from harmony_tokenizers_m21 import ChordSymbolTokenizer, RootTypeTokenizer, \\\n",
    "    PitchClassTokenizer, RootPCTokenizer, GCTRootPCTokenizer, \\\n",
    "    GCTSymbolTokenizer, GCTRootTypeTokenizer, MelodyPitchTokenizer, \\\n",
    "    MergedMelHarmTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BartForConditionalGeneration, BartConfig, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from models import TextGuidedHarmonizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chordSymbolTokenizer = ChordSymbolTokenizer.from_pretrained('saved_tokenizers/ChordSymbolTokenizer')\n",
    "rootTypeTokenizer = RootTypeTokenizer.from_pretrained('saved_tokenizers/RootTypeTokenizer')\n",
    "pitchClassTokenizer = PitchClassTokenizer.from_pretrained('saved_tokenizers/PitchClassTokenizer')\n",
    "rootPCTokenizer = RootPCTokenizer.from_pretrained('saved_tokenizers/RootPCTokenizer')\n",
    "melodyPitchTokenizer = MelodyPitchTokenizer.from_pretrained('saved_tokenizers/MelodyPitchTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_chordSymbolTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, chordSymbolTokenizer)\n",
    "m_rootTypeTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, rootTypeTokenizer)\n",
    "m_pitchClassTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, pitchClassTokenizer)\n",
    "m_rootPCTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, rootPCTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = m_chordSymbolTokenizer\n",
    "# tokenizer_name = 'ChordSymbolTokenizer'\n",
    "# tokenizer = m_rootTypeTokenizer\n",
    "# tokenizer_name = 'RootTypeTokenizer'\n",
    "# tokenizer = m_pitchClassTokenizer\n",
    "# tokenizer_name = 'PitchClassTokenizer'\n",
    "tokenizer = m_rootPCTokenizer\n",
    "tokenizer_name = 'RootPCTokenizer'\n",
    "\n",
    "root_dir = '/media/maindisk/maximos/data/hooktheory_test'\n",
    "\n",
    "dataset = SeparatedMelHarmTextDataset(\n",
    "    root_dir,\n",
    "    tokenizer,\n",
    "    max_length=512,\n",
    "    num_bars=64,\n",
    "    description_mode='specific_chord',\n",
    "    alteration=True\n",
    ")\n",
    "\n",
    "def create_data_collator(tokenizer, model):\n",
    "    return MelHarmTextCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
    "# end create_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartDecoder(\n",
       "  (embed_tokens): BartScaledWordEmbedding(221, 512, padding_idx=1)\n",
       "  (embed_positions): BartLearnedPositionalEmbedding(514, 512)\n",
       "  (layers): ModuleList(\n",
       "    (0-7): 8 x BartDecoderLayer(\n",
       "      (self_attn): BartSdpaAttention(\n",
       "        (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (activation_fn): GELUActivation()\n",
       "      (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder_attn): BartSdpaAttention(\n",
       "        (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_config = BartConfig(\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    decoder_start_token_id=tokenizer.bos_token_id,\n",
    "    forced_eos_token_id=tokenizer.eos_token_id,\n",
    "    max_position_embeddings=512,\n",
    "    encoder_layers=8,\n",
    "    encoder_attention_heads=8,\n",
    "    encoder_ffn_dim=512,\n",
    "    decoder_layers=8,\n",
    "    decoder_attention_heads=8,\n",
    "    decoder_ffn_dim=512,\n",
    "    d_model=512,\n",
    "    encoder_layerdrop=0.3,\n",
    "    decoder_layerdrop=0.3,\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "bart = BartForConditionalGeneration(bart_config)\n",
    "\n",
    "bart_path = 'saved_models/bart/' + tokenizer_name + '/' + tokenizer_name + '.pt'\n",
    "checkpoint = torch.load(bart_path, map_location=device_name, weights_only=True)\n",
    "bart.load_state_dict(checkpoint)\n",
    "\n",
    "bart.to(device)\n",
    "bart.eval()\n",
    "\n",
    "bart_encoder, bart_decoder = bart.get_encoder(), bart.get_decoder()\n",
    "bart_encoder.to(device)\n",
    "bart_decoder.to(device)\n",
    "\n",
    "# # Freeze BART parameters\n",
    "# for param in bart_encoder.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in bart_encoder.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = create_data_collator(tokenizer, model=bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/music21/stream/base.py:3694: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'harmony_input_ids', 'labels', 'decoder_input_ids', 'txt'])\n"
     ]
    }
   ],
   "source": [
    "print(b.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-100,    6,   95,  197,  213,  216,  111,  204,  220,  211,    6,   95,\n",
      "          197,  213,  216,  111,  204,  220,  211,    6,   95,  197,  213,  216,\n",
      "          111,  202,  218,  209,    6,   95,  204,  220,  211,    6,   95,  197,\n",
      "          213,  216,  111,  204,  220,  211,    6,   95,  197,  213,  216,  111,\n",
      "          204,  220,  211,    6,   95,  197,  213,  216,  111,  202,  218,  209,\n",
      "            6,   95,  197,  211,  213,  216,  220,    1]])\n"
     ]
    }
   ],
   "source": [
    "print(b['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = TextGuidedHarmonizationModel(bart, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_ids = b['input_ids'].to(device)\n",
    "melody_attention_mask = b['attention_mask'].to(device)\n",
    "harmony_input_ids = b['harmony_input_ids'].to(device)\n",
    "labels = b['labels'].to(device)\n",
    "texts = b['txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat_h:  torch.Size([1, 102, 512])\n",
      "labels:  torch.Size([1, 68])\n"
     ]
    }
   ],
   "source": [
    "output = model(model_input_ids, melody_attention_mask, harmony_input_ids, texts, labels=labels)\n",
    "decoder_loss = output['loss']\n",
    "decoder_logits = output['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0673, grad_fn=<NllLossBackward0>)\n",
      "tensor([[[ -8.8498,  -8.9703,   2.5205,  ...,   0.3193,   0.6228,   0.6747],\n",
      "         [-22.2938, -22.1433,  -2.1604,  ...,   0.3856,  -0.9911,   0.7216],\n",
      "         [-20.5718, -20.5356,  -1.4832,  ...,  -2.3109,  -3.1869,  -2.1093],\n",
      "         ...,\n",
      "         [-17.3761, -17.5985,  -2.0772,  ...,   1.9245,  -1.8549,  -1.1557],\n",
      "         [-19.1630, -19.1568,  -2.4330,  ...,   3.9359,   6.1086,   8.8422],\n",
      "         [-18.7110, -18.9539,  -3.0130,  ...,  -2.3950,  -2.7397,   0.4671]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_loss)\n",
    "print(decoder_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# Define optimizer (only update trainable parameters)\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "num_training_steps = len(dataloader) * num_epochs\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
