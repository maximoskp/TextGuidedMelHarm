{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import SeparatedMelHarmTextDataset, MelHarmTextCollatorForSeq2Seq\n",
    "import os\n",
    "import numpy as np\n",
    "from harmony_tokenizers_m21 import ChordSymbolTokenizer, RootTypeTokenizer, \\\n",
    "    PitchClassTokenizer, RootPCTokenizer, GCTRootPCTokenizer, \\\n",
    "    GCTSymbolTokenizer, GCTRootTypeTokenizer, MelodyPitchTokenizer, \\\n",
    "    MergedMelHarmTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BartForConditionalGeneration, BartConfig, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from models import TextGuidedHarmonizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chordSymbolTokenizer = ChordSymbolTokenizer.from_pretrained('saved_tokenizers/ChordSymbolTokenizer')\n",
    "rootTypeTokenizer = RootTypeTokenizer.from_pretrained('saved_tokenizers/RootTypeTokenizer')\n",
    "pitchClassTokenizer = PitchClassTokenizer.from_pretrained('saved_tokenizers/PitchClassTokenizer')\n",
    "rootPCTokenizer = RootPCTokenizer.from_pretrained('saved_tokenizers/RootPCTokenizer')\n",
    "melodyPitchTokenizer = MelodyPitchTokenizer.from_pretrained('saved_tokenizers/MelodyPitchTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_chordSymbolTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, chordSymbolTokenizer)\n",
    "m_rootTypeTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, rootTypeTokenizer)\n",
    "m_pitchClassTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, pitchClassTokenizer)\n",
    "m_rootPCTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, rootPCTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = m_chordSymbolTokenizer\n",
    "# tokenizer_name = 'ChordSymbolTokenizer'\n",
    "# tokenizer = m_rootTypeTokenizer\n",
    "# tokenizer_name = 'RootTypeTokenizer'\n",
    "# tokenizer = m_pitchClassTokenizer\n",
    "# tokenizer_name = 'PitchClassTokenizer'\n",
    "tokenizer = m_rootPCTokenizer\n",
    "tokenizer_name = 'RootPCTokenizer'\n",
    "\n",
    "description_mode = 'specific_chord'\n",
    "\n",
    "train_dir = '/media/maindisk/maximos/data/hooktheory_train'\n",
    "test_dir = '/media/maindisk/maximos/data/hooktheory_test'\n",
    "\n",
    "train_dataset = SeparatedMelHarmTextDataset(\n",
    "    train_dir,\n",
    "    tokenizer,\n",
    "    max_length=512,\n",
    "    num_bars=64,\n",
    "    description_mode=description_mode,\n",
    "    alteration=True\n",
    ")\n",
    "\n",
    "test_dataset = SeparatedMelHarmTextDataset(\n",
    "    test_dir,\n",
    "    tokenizer,\n",
    "    max_length=512,\n",
    "    num_bars=64,\n",
    "    description_mode=description_mode,\n",
    "    alteration=True\n",
    ")\n",
    "\n",
    "def create_data_collator(tokenizer, model):\n",
    "    return MelHarmTextCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
    "# end create_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device_name = 'cpu'\n",
    "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_config = BartConfig(\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    decoder_start_token_id=tokenizer.bos_token_id,\n",
    "    forced_eos_token_id=tokenizer.eos_token_id,\n",
    "    max_position_embeddings=512,\n",
    "    encoder_layers=8,\n",
    "    encoder_attention_heads=8,\n",
    "    encoder_ffn_dim=512,\n",
    "    decoder_layers=8,\n",
    "    decoder_attention_heads=8,\n",
    "    decoder_ffn_dim=512,\n",
    "    d_model=512,\n",
    "    encoder_layerdrop=0.3,\n",
    "    decoder_layerdrop=0.3,\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "bart = BartForConditionalGeneration(bart_config)\n",
    "\n",
    "model = TextGuidedHarmonizationModel(bart, device=device)\n",
    "\n",
    "model_path = 'saved_models/bart_text_cvae/' + tokenizer_name + '/' +description_mode+'/' + tokenizer_name + '.pt'\n",
    "checkpoint = torch.load(model_path, map_location=device_name, weights_only=True)\n",
    "model.load_state_dict(checkpoint) # TODO: map location\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
